{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available now: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jo/miniconda3/lib/python3.9/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination (Triggered internally at  /opt/conda/conda-bld/pytorch_1646756402876/work/c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn.metrics\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from utils import set_seed\n",
    "\n",
    "# def set_seed(seed = 1234):\n",
    "#     '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "#     This is for REPRODUCIBILITY.'''\n",
    "#     np.random.seed(seed)\n",
    "#     random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     # When running on the CuDNN backend, two further options must be set\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "#     # Set a fixed value for the hash seed\n",
    "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device available now:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input time_0 shape: torch.Size([4, 4])\n",
      "input time_1 shape: torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "# ==== STATICS ====\n",
    "n_inputs = 4\n",
    "n_neurons = 1\n",
    "# =================\n",
    "\n",
    "# RNN inputs\n",
    "input0 = torch.tensor([[0, 1, 2, 0], [3, 4, 5, 0], [6, 7, 8, 0], [9, 0, 1, 0]], dtype = torch.float)\n",
    "print('input time_0 shape:', input0.shape)\n",
    "\n",
    "input1 = torch.tensor([[9, 8, 7, 0], [3, 4, 5, 0], [6, 7, 8, 0], [9, 0, 1, 0]], dtype = torch.float)\n",
    "print('input time_1 shape:', input1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [00:03, 2734109.58it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 5259883.94it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1649664it [00:00, 2314536.89it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5120it [00:00, 4094344.42it/s]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Customized transform (transforms to tensor, here you can normalize, perform Data Augmentation etc.)\n",
    "my_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download data\n",
    "mnist_train = torchvision.datasets.MNIST('data', train = True, download=True, transform=my_transform)\n",
    "mnist_test = torchvision.datasets.MNIST('data', train = False, download=True, transform=my_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Neural Network\n",
    "class VanillaRNN_MNIST(nn.Module):\n",
    "    def __init__(self, batch_size, input_size, hidden_size, output_size):\n",
    "        super(VanillaRNN_MNIST, self).__init__()\n",
    "        self.batch_size, self.input_size, self.hidden_size, self.output_size = batch_size, input_size, hidden_size, output_size\n",
    "        \n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_size)\n",
    "        # Fully Connected Layer\n",
    "        self.layer = nn.Linear(hidden_size, self.output_size)\n",
    "    \n",
    "    def forward(self, images, prints=False):\n",
    "        if prints: print('Original Images Shape:', images.shape)\n",
    "        \n",
    "        images = images.permute(1, 0, 2)\n",
    "        if prints: print('Permuted Imaged Shape:', images.shape)\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        hidden_state = torch.zeros(1, self.batch_size, self.hidden_size)\n",
    "        if prints: print('Initial hidden state Shape:', hidden_state.shape)\n",
    "        \n",
    "        # Creating RNN\n",
    "        hidden_outputs, hidden_state = self.rnn(images, hidden_state)\n",
    "        \n",
    "        # Log probabilities\n",
    "        out = self.layer(hidden_state)\n",
    "        \n",
    "        if prints:\n",
    "            print('----hidden_outputs shape:', hidden_outputs.shape, '\\n' +\n",
    "                  '----final hidden state:', hidden_state.shape, '\\n' +\n",
    "                  '----out shape:', out.shape)\n",
    "        \n",
    "        # Reshaped out\n",
    "        out = out.view(-1, self.output_size)\n",
    "        if prints: print('Out Final Shape:', out.shape)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== STATICS ====\n",
    "batch_size = 64        # how many images to be trained in one iteration\n",
    "input_size = 28        # image 28 by 28\n",
    "hidden_size = 150      # can be changed to any number: neurons\n",
    "output_size = 10       # 10 different digits\n",
    "# ================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original images shape: torch.Size([64, 1, 28, 28])\n",
      "changed images shape: torch.Size([64, 28, 28])\n",
      "labels shape: torch.Size([64]) \n",
      "\n",
      "Original Images Shape: torch.Size([64, 28, 28])\n",
      "Permuted Imaged Shape: torch.Size([28, 64, 28])\n",
      "Initial hidden state Shape: torch.Size([1, 64, 150])\n",
      "----hidden_outputs shape: torch.Size([28, 64, 150]) \n",
      "----final hidden state: torch.Size([1, 64, 150]) \n",
      "----out shape: torch.Size([1, 64, 10])\n",
      "Out Final Shape: torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# Create a train_loader to select a batch from it\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=64)\n",
    "\n",
    "# Select one full batch from the data\n",
    "images_example, labels_example = next(iter(train_loader))\n",
    "print('original images shape:', images_example.shape)\n",
    "\n",
    "# Reshape\n",
    "images_example = images_example.view(-1, 28, 28)\n",
    "print('changed images shape:', images_example.shape)\n",
    "print('labels shape:', labels_example.shape, '\\n')\n",
    "\n",
    "# Creating the model\n",
    "model_example = VanillaRNN_MNIST(batch_size, input_size, hidden_size, output_size)\n",
    "\n",
    "\n",
    "out = model_example(images_example, prints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len parameters: 6 \n",
      "Parameters 0 - U: torch.Size([150, 28]) \n",
      "Parameters 1 - W: torch.Size([150, 150]) \n",
      "Parameters 2 - Bias: torch.Size([150]) \n",
      "Parameters 3 - Bias: torch.Size([150]) \n",
      "Parameters 4 - FNN weights: torch.Size([10, 150]) \n",
      "Parameters 5 - Predictions: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Understand Model Parameters\n",
    "print('Len parameters:', len(list(model_example.parameters())), '\\n' +\n",
    "      'Parameters 0 - U:', list(model_example.parameters())[0].shape, '\\n' +\n",
    "      'Parameters 1 - W:', list(model_example.parameters())[1].shape, '\\n' +\n",
    "      'Parameters 2 - Bias:', list(model_example.parameters())[2].shape, '\\n' +\n",
    "      'Parameters 3 - Bias:', list(model_example.parameters())[3].shape, '\\n' +\n",
    "      'Parameters 4 - FNN weights:', list(model_example.parameters())[4].shape, '\\n' +\n",
    "      'Parameters 5 - Predictions:', list(model_example.parameters())[5].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(out, actual_labels, batchSize):\n",
    "    '''Saves the Accuracy of the batch.\n",
    "    Takes in the log probabilities, actual label and the batchSize (to average the score).'''\n",
    "    predictions = out.max(dim=1)[1]\n",
    "    correct = (predictions == actual_labels).sum().item()\n",
    "    accuracy = correct/batch_size\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, train_data, test_data, batchSize=64, num_epochs=1, learning_rate=0.001):\n",
    "    \n",
    "    '''Trains the model and computes the average accuracy for train and test data.'''\n",
    "    \n",
    "    print('Get data ready...')\n",
    "    # Create dataloader for training dataset - so we can train on multiple batches\n",
    "    # Shuffle after every epoch\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batchSize, shuffle=True, drop_last=True)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batchSize, shuffle=True, drop_last=True)\n",
    "    \n",
    "    # Create criterion and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    \n",
    "    print('Training started...')\n",
    "    # Train the data multiple times\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Save Train and Test Loss\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        \n",
    "        # Set model in training mode:\n",
    "        model.train()\n",
    "        \n",
    "        for k, (images, labels) in enumerate(train_loader):\n",
    "            \n",
    "            # Get rid of the channel\n",
    "            images = images.view(-1, 28, 28)\n",
    "            \n",
    "            # Create log probabilities\n",
    "            out = model(images)\n",
    "            # Clears the gradients from previous iteration\n",
    "            optimizer.zero_grad()\n",
    "            # Computes loss: how far is the prediction from the actual?\n",
    "            loss = criterion(out, labels)\n",
    "            # Computes gradients for neurons\n",
    "            loss.backward()\n",
    "            # Updates the weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Save Loss & Accuracy after each iteration\n",
    "            train_loss += loss.item()\n",
    "            train_acc += get_accuracy(out, labels, batchSize)\n",
    "            \n",
    "        \n",
    "        # Print Average Train Loss & Accuracy after each epoch\n",
    "        print('TRAIN | Epoch: {}/{} | Loss: {:.2f} | Accuracy: {:.2f}'.format(epoch+1, num_epochs, train_loss/k, train_acc/k))\n",
    "            \n",
    "            \n",
    "    print('Testing Started...')\n",
    "    # Save Test Accuracy\n",
    "    test_acc = 0\n",
    "    # Evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    for k, (images, labels) in enumerate(test_loader):\n",
    "        # Get rid of the channel\n",
    "        images = images.view(-1, 28, 28)\n",
    "        \n",
    "        # Create logit predictions\n",
    "        out = model(images)\n",
    "        # Add Accuracy of this batch\n",
    "        test_acc += get_accuracy(out, labels, batchSize)\n",
    "        \n",
    "    # Print Final Test Accuracy\n",
    "    print('TEST | Average Accuracy per {} Loaders: {:.5f}'.format(k, test_acc/k) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data ready...\n",
      "Training started...\n",
      "TRAIN | Epoch: 1/10 | Loss: 0.66 | Accuracy: 0.79\n",
      "TRAIN | Epoch: 2/10 | Loss: 0.31 | Accuracy: 0.91\n",
      "TRAIN | Epoch: 3/10 | Loss: 0.23 | Accuracy: 0.93\n",
      "TRAIN | Epoch: 4/10 | Loss: 0.20 | Accuracy: 0.94\n",
      "TRAIN | Epoch: 5/10 | Loss: 0.17 | Accuracy: 0.95\n",
      "TRAIN | Epoch: 6/10 | Loss: 0.16 | Accuracy: 0.96\n",
      "TRAIN | Epoch: 7/10 | Loss: 0.14 | Accuracy: 0.96\n",
      "TRAIN | Epoch: 8/10 | Loss: 0.13 | Accuracy: 0.96\n",
      "TRAIN | Epoch: 9/10 | Loss: 0.12 | Accuracy: 0.97\n",
      "TRAIN | Epoch: 10/10 | Loss: 0.12 | Accuracy: 0.97\n",
      "Testing Started...\n",
      "TEST | Average Accuracy per 155 Loaders: 0.96784\n"
     ]
    }
   ],
   "source": [
    "# ==== STATICS ====\n",
    "batch_size=64\n",
    "input_size=28\n",
    "hidden_size=150\n",
    "output_size=10\n",
    "\n",
    "# Instantiate the model\n",
    "vanilla_rnn = VanillaRNN_MNIST(batch_size, input_size, hidden_size, output_size)\n",
    "\n",
    "# ==== TRAIN ====\n",
    "train_network(vanilla_rnn, mnist_train, mnist_test, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6645d380ff3418b375956c202e769480ea4e651fcf237b9e79e4d886978df71"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
